"""
Streamlit web application for cross-platform user identification.
"""

import streamlit as st
import pandas as pd
import numpy as np
import os
import yaml
import json
import time
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import networkx as nx
from PIL import Image
import io
import base64
from typing import Dict, List, Optional, Union, Tuple, Any

# Wrap PyTorch imports in try-except to avoid Streamlit file watcher errors
try:
    # Import project modules
    from src.models.cross_platform_identifier import CrossPlatformUserIdentifier
    from src.data.data_loader import DataLoader
    from src.utils.visualizer import Visualizer
except RuntimeError as e:
    if "__path__._path" in str(e):
        # This is the PyTorch/Streamlit file watcher error, we can ignore it
        # and try importing again
        from src.models.cross_platform_identifier import CrossPlatformUserIdentifier
        from src.data.data_loader import DataLoader
        from src.utils.visualizer import Visualizer

# Set page config
st.set_page_config(
    page_title="LinkedIn-Instagram User Identification",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize session state
if 'identifier' not in st.session_state:
    st.session_state.identifier = None
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
if 'embeddings_generated' not in st.session_state:
    st.session_state.embeddings_generated = False
if 'matches' not in st.session_state:
    st.session_state.matches = None
if 'metrics' not in st.session_state:
    st.session_state.metrics = None
if 'visualizer' not in st.session_state:
    st.session_state.visualizer = Visualizer(use_plotly=True)

def load_data():
    """Load data from selected sources."""
    st.header("Data Loading")

    data_source = st.radio(
        "Select data source",
        ["LinkedIn Scraping", "Instagram Scraping", "Local Files"]
    )

    if data_source == "LinkedIn Scraping":
        with st.form("linkedin_scraping_form"):
            st.subheader("Scrape LinkedIn Data")
            st.warning("LinkedIn scraping requires Selenium and a LinkedIn account. Use at your own risk and ensure compliance with LinkedIn's terms of service.")

            email = st.text_input("LinkedIn Email")
            password = st.text_input("LinkedIn Password", type="password")
            profile_urls = st.text_area("LinkedIn Profile URLs (one per line)")
            headless = st.checkbox("Run in headless mode", value=True)

            scrape_button = st.form_submit_button("Scrape LinkedIn")

            if scrape_button:
                if not email or not password or not profile_urls:
                    st.error("Please provide email, password, and at least one profile URL.")
                else:
                    try:
                        from src.data.linkedin_scraper import LinkedInScraper

                        # Parse profile URLs
                        profile_url_list = [url.strip() for url in profile_urls.split('\n') if url.strip()]

                        with st.spinner(f"Scraping {len(profile_url_list)} LinkedIn profiles..."):
                            # Initialize scraper
                            scraper = LinkedInScraper(headless=headless, output_dir="data/linkedin")

                            # Login
                            if scraper.login(email, password):
                                # Scrape profiles
                                scraper.scrape_profiles(profile_url_list)

                                # Close browser
                                scraper.close()

                                st.success(f"Successfully scraped {len(profile_url_list)} LinkedIn profiles. Data saved to 'data/linkedin/'.")

                                # Initialize identifier
                                if st.session_state.identifier is None:
                                    st.session_state.identifier = CrossPlatformUserIdentifier()

                                # Load data
                                st.session_state.identifier.load_data(
                                    platform1_path="data/linkedin",
                                    platform2_path="data/instagram" if os.path.exists("data/instagram/profiles.csv") else None,
                                    ground_truth_path=None
                                )

                                st.session_state.data_loaded = True

                                # Show sample data
                                st.subheader("Sample LinkedIn profiles")
                                st.dataframe(st.session_state.identifier.data["linkedin"]["profiles"].head())
                            else:
                                st.error("Failed to login to LinkedIn. Please check your credentials.")
                    except Exception as e:
                        st.error(f"Error scraping LinkedIn profiles: {str(e)}")
                        st.info("Make sure you have installed all required dependencies: pip install selenium webdriver-manager")

    elif data_source == "Instagram Scraping":
        with st.form("instagram_scraping_form"):
            st.subheader("Scrape Instagram Data")
            st.warning("Instagram scraping requires Selenium and an Instagram account. Use at your own risk and ensure compliance with Instagram's terms of service.")

            username = st.text_input("Instagram Username")
            password = st.text_input("Instagram Password", type="password")
            target_usernames = st.text_area("Target Instagram Usernames (one per line)")
            headless = st.checkbox("Run in headless mode", value=True)

            scrape_button = st.form_submit_button("Scrape Instagram")

            if scrape_button:
                if not username or not password or not target_usernames:
                    st.error("Please provide username, password, and at least one target username.")
                else:
                    try:
                        from src.data.instagram_scraper import InstagramScraper

                        # Parse target usernames
                        username_list = [uname.strip() for uname in target_usernames.split('\n') if uname.strip()]

                        with st.spinner(f"Scraping {len(username_list)} Instagram profiles..."):
                            # Initialize scraper
                            scraper = InstagramScraper(headless=headless, output_dir="data/instagram")

                            # Login
                            if scraper.login(username, password):
                                # Scrape profiles
                                scraper.scrape_profiles(username_list)

                                # Close browser
                                scraper.close()

                                st.success(f"Successfully scraped {len(username_list)} Instagram profiles. Data saved to 'data/instagram/'.")

                                # Initialize identifier
                                if st.session_state.identifier is None:
                                    st.session_state.identifier = CrossPlatformUserIdentifier()

                                # Load data
                                st.session_state.identifier.load_data(
                                    platform1_path="data/instagram",
                                    platform2_path="data/linkedin" if os.path.exists("data/linkedin/profiles.csv") else None,
                                    ground_truth_path=None
                                )

                                st.session_state.data_loaded = True

                                # Show sample data
                                st.subheader("Sample Instagram profiles")
                                st.dataframe(st.session_state.identifier.data["instagram"]["profiles"].head())
                            else:
                                st.error("Failed to login to Instagram. Please check your credentials.")
                    except Exception as e:
                        st.error(f"Error scraping Instagram profiles: {str(e)}")
                        st.info("Make sure you have installed all required dependencies: pip install selenium webdriver-manager")

    elif data_source == "Local Files":
        with st.form("local_files_form"):
            st.subheader("Load Data from Local Files")

            platform1_path = st.text_input("Platform 1 directory path", "data/linkedin")
            platform2_path = st.text_input("Platform 2 directory path", "data/instagram")
            ground_truth_path = st.text_input("Ground truth file path", "data/ground_truth.csv")

            load_button = st.form_submit_button("Load Data")

            if load_button:
                # Check if paths exist
                if not os.path.exists(platform1_path):
                    st.error(f"Platform 1 directory not found: {platform1_path}")
                    return

                if not os.path.exists(platform2_path):
                    st.error(f"Platform 2 directory not found: {platform2_path}")
                    return

                with st.spinner("Loading data..."):
                    # Initialize identifier
                    if st.session_state.identifier is None:
                        st.session_state.identifier = CrossPlatformUserIdentifier()

                    # Load data
                    try:
                        st.session_state.identifier.load_data(
                            platform1_path=platform1_path,
                            platform2_path=platform2_path,
                            ground_truth_path=ground_truth_path if os.path.exists(ground_truth_path) else None
                        )

                        st.session_state.data_loaded = True
                        st.success("Data loaded successfully")

                        # Show sample data
                        platform_names = list(st.session_state.identifier.data.keys())
                        if len(platform_names) >= 2:
                            platform1_name = platform_names[0]
                            platform2_name = platform_names[1]

                            st.subheader(f"Sample profiles from {platform1_name}")
                            st.dataframe(st.session_state.identifier.data[platform1_name]['profiles'].head())

                            st.subheader(f"Sample profiles from {platform2_name}")
                            st.dataframe(st.session_state.identifier.data[platform2_name]['profiles'].head())

                            if hasattr(st.session_state.identifier.data_loader, 'ground_truth'):
                                st.subheader("Sample ground truth")
                                st.dataframe(st.session_state.identifier.data_loader.ground_truth.head())

                    except Exception as e:
                        st.error(f"Error loading data: {e}")

    elif data_source == "LinkedIn Scraping":
        with st.form("linkedin_scraping_form"):
            st.subheader("Scrape LinkedIn Data")
            st.warning("LinkedIn scraping requires Selenium and a LinkedIn account. Use at your own risk and ensure compliance with LinkedIn's terms of service.")

            email = st.text_input("LinkedIn Email")
            password = st.text_input("LinkedIn Password", type="password")
            profile_urls = st.text_area("LinkedIn Profile URLs (one per line)")
            headless = st.checkbox("Run in headless mode", value=True)

            scrape_button = st.form_submit_button("Scrape LinkedIn")

            if scrape_button:
                if not email or not password or not profile_urls:
                    st.error("Please provide email, password, and at least one profile URL.")
                else:
                    try:
                        from src.data.linkedin_scraper import LinkedInScraper

                        # Parse profile URLs
                        profile_url_list = [url.strip() for url in profile_urls.split('\n') if url.strip()]

                        with st.spinner(f"Scraping {len(profile_url_list)} LinkedIn profiles..."):
                            # Initialize scraper
                            scraper = LinkedInScraper(headless=headless, output_dir="data/linkedin")

                            # Login
                            if scraper.login(email, password):
                                # Scrape profiles
                                scraper.scrape_profiles(profile_url_list)

                                # Close browser
                                scraper.close()

                                st.success(f"Successfully scraped {len(profile_url_list)} LinkedIn profiles. Data saved to 'data/linkedin/'.")

                                # Initialize identifier
                                if st.session_state.identifier is None:
                                    st.session_state.identifier = CrossPlatformUserIdentifier()

                                # Load data
                                st.session_state.identifier.load_data(
                                    platform1_path="data/linkedin",
                                    platform2_path="data/instagram" if os.path.exists("data/instagram/profiles.csv") else None,
                                    ground_truth_path=None
                                )

                                st.session_state.data_loaded = True

                                # Show sample data
                                st.subheader("Sample LinkedIn profiles")
                                st.dataframe(st.session_state.identifier.data["linkedin"]["profiles"].head())
                            else:
                                st.error("Failed to login to LinkedIn. Please check your credentials.")
                    except Exception as e:
                        st.error(f"Error scraping LinkedIn profiles: {str(e)}")
                        st.info("Make sure you have installed all required dependencies: pip install selenium webdriver-manager")

    elif data_source == "Instagram Scraping":
        with st.form("instagram_scraping_form"):
            st.subheader("Scrape Instagram Data")
            st.warning("Instagram scraping requires Selenium and an Instagram account. Use at your own risk and ensure compliance with Instagram's terms of service.")

            username = st.text_input("Instagram Username")
            password = st.text_input("Instagram Password", type="password")
            target_usernames = st.text_area("Target Instagram Usernames (one per line)")
            headless = st.checkbox("Run in headless mode", value=True)

            scrape_button = st.form_submit_button("Scrape Instagram")

            if scrape_button:
                if not username or not password or not target_usernames:
                    st.error("Please provide username, password, and at least one target username.")
                else:
                    try:
                        from src.data.instagram_scraper import InstagramScraper

                        # Parse target usernames
                        username_list = [uname.strip() for uname in target_usernames.split('\n') if uname.strip()]

                        with st.spinner(f"Scraping {len(username_list)} Instagram profiles..."):
                            # Initialize scraper
                            scraper = InstagramScraper(headless=headless, output_dir="data/instagram")

                            # Login
                            if scraper.login(username, password):
                                # Scrape profiles
                                scraper.scrape_profiles(username_list)

                                # Close browser
                                scraper.close()

                                st.success(f"Successfully scraped {len(username_list)} Instagram profiles. Data saved to 'data/instagram/'.")

                                # Initialize identifier
                                if st.session_state.identifier is None:
                                    st.session_state.identifier = CrossPlatformUserIdentifier()

                                # Load data
                                st.session_state.identifier.load_data(
                                    platform1_path="data/instagram",
                                    platform2_path="data/linkedin" if os.path.exists("data/linkedin/profiles.csv") else None,
                                    ground_truth_path=None
                                )

                                st.session_state.data_loaded = True

                                # Show sample data
                                st.subheader("Sample Instagram profiles")
                                st.dataframe(st.session_state.identifier.data["instagram"]["profiles"].head())
                            else:
                                st.error("Failed to login to Instagram. Please check your credentials.")
                    except Exception as e:
                        st.error(f"Error scraping Instagram profiles: {str(e)}")
                        st.info("Make sure you have installed all required dependencies: pip install selenium webdriver-manager")

def run_analysis():
    """Run analysis on loaded data."""
    st.header("Analysis")

    if not st.session_state.data_loaded:
        st.warning("Please load data first from the Data Loading tab.")
        st.info("You need to scrape both LinkedIn and Instagram data to perform cross-platform analysis.")
        return

    with st.form("analysis_form"):
        st.subheader("Configure Analysis")

        # Get platform names
        platform_names = list(st.session_state.identifier.data.keys())
        if len(platform_names) < 2:
            st.error("Both LinkedIn and Instagram data are required for analysis.")
            st.info("Please go to the Data Loading tab and scrape data from both platforms.")
            return

        # Set platform names
        linkedin_exists = "linkedin" in platform_names
        instagram_exists = "instagram" in platform_names

        if linkedin_exists and instagram_exists:
            platform1_name = "linkedin"
            platform2_name = "instagram"
            st.success("Found data for both LinkedIn and Instagram.")
        else:
            missing_platforms = []
            if not linkedin_exists:
                missing_platforms.append("LinkedIn")
            if not instagram_exists:
                missing_platforms.append("Instagram")

            st.error(f"Missing data for {', '.join(missing_platforms)}.")
            st.info("Please go to the Data Loading tab and scrape data from the missing platform(s).")

            # Use available platforms for now
            platform1_name = platform_names[0]
            platform2_name = platform_names[1] if len(platform_names) > 1 else platform_names[0]

        # Feature extraction parameters
        st.subheader("Feature Extraction")

        network_method = st.selectbox("Network Embedding Method",
                                    ["node2vec"],
                                    index=0,
                                    help="node2vec is used to generate network embeddings from user connections.")

        semantic_model = st.selectbox("Semantic Model", [
            "sentence-transformers/all-MiniLM-L6-v2"
        ], index=0,
        help="This model is used to generate semantic embeddings from user posts and profile text.")

        # Matching parameters
        st.subheader("User Matching")

        matching_method = st.selectbox("Matching Method", ["cosine"], index=0,
                                     help="Cosine similarity is used to measure the similarity between user embeddings.")

        matching_threshold = st.slider("Matching Threshold", 0.1, 0.9, 0.7, 0.05,
                                     help="Users with similarity above this threshold are considered matches.")

        # Run analysis
        run_button = st.form_submit_button("Run Analysis")

        if run_button:
            with st.spinner("Running analysis..."):
                # Update configuration
                config = {
                    'network_method': network_method,
                    'semantic_model_name': semantic_model,
                    'matching_method': matching_method,
                    'matching_threshold': matching_threshold
                }

                # Update identifier configuration
                st.session_state.identifier.config.update(config)

                # Preprocess data
                st.session_state.identifier.preprocess()

                # Extract features
                st.session_state.identifier.extract_features()
                st.session_state.embeddings_generated = True

                # Match users
                matches = st.session_state.identifier.match_users(
                    platform1_name=platform1_name,
                    platform2_name=platform2_name,
                    embedding_type='fusion'
                )
                st.session_state.matches = matches

                # Evaluate if ground truth is available
                if hasattr(st.session_state.identifier.data_loader, 'ground_truth'):
                    metrics = st.session_state.identifier.evaluate()
                    st.session_state.metrics = metrics

                st.success("Analysis completed successfully")

def display_results():
    """Display LinkedIn-Instagram matching results."""
    st.header("LinkedIn-Instagram Matching Results")

    if not st.session_state.data_loaded:
        st.warning("Please load data first from the Data Loading tab.")
        st.info("You need to scrape both LinkedIn and Instagram data to view matching results.")
        return

    if not st.session_state.embeddings_generated:
        st.warning("Please run analysis first on the Analysis tab.")
        st.info("This will generate the embeddings and matches needed to view results.")
        return

    # Get platform names
    platform_names = list(st.session_state.identifier.data.keys())

    # Check if both LinkedIn and Instagram data are available
    linkedin_exists = "linkedin" in platform_names
    instagram_exists = "instagram" in platform_names

    if not linkedin_exists or not instagram_exists:
        missing_platforms = []
        if not linkedin_exists:
            missing_platforms.append("LinkedIn")
        if not instagram_exists:
            missing_platforms.append("Instagram")

        st.error(f"Missing data for {', '.join(missing_platforms)}.")
        st.info("Please go to the Data Loading tab and scrape data from the missing platform(s).")
        return

    # Set platform names
    platform1_name = "linkedin"
    platform2_name = "instagram"

    st.subheader("Cross-Platform User Matches")
    st.write("These are the users identified as potentially being the same person across LinkedIn and Instagram:")
    st.write("Higher confidence scores indicate a stronger likelihood of being the same person.")

    # Display matches
    if st.session_state.matches is not None:
        st.subheader("User Matches")
        st.dataframe(st.session_state.matches)

        # Download matches as CSV
        csv = st.session_state.matches.to_csv(index=False)
        st.download_button(
            label="Download Matches as CSV",
            data=csv,
            file_name="matches.csv",
            mime="text/csv"
        )

    # Display evaluation metrics
    if st.session_state.metrics is not None:
        st.subheader("Evaluation Metrics")

        match_key = f"{platform1_name}_{platform2_name}_fusion"
        if match_key in st.session_state.metrics:
            metrics = st.session_state.metrics[match_key]

            # Create metrics display
            col1, col2, col3 = st.columns(3)
            col1.metric("Precision", f"{metrics['precision']:.4f}")
            col2.metric("Recall", f"{metrics['recall']:.4f}")
            col3.metric("F1 Score", f"{metrics['f1']:.4f}")

            # Display confusion matrix
            if 'confusion_matrix' in st.session_state.identifier.evaluator.metrics:
                st.subheader("Confusion Matrix")
                cm = np.array(st.session_state.identifier.evaluator.metrics['confusion_matrix']['matrix'])

                fig = go.Figure(data=go.Heatmap(
                    z=cm,
                    x=['Negative', 'Positive'],
                    y=['Negative', 'Positive'],
                    colorscale='Blues',
                    showscale=False
                ))

                fig.update_layout(
                    title=f"Confusion Matrix (Threshold = {metrics['best_threshold']:.2f})",
                    xaxis_title="Predicted",
                    yaxis_title="Actual"
                )

                st.plotly_chart(fig)

            # Display ROC curve
            if 'roc_curve' in st.session_state.identifier.evaluator.metrics:
                st.subheader("ROC Curve")
                roc = st.session_state.identifier.evaluator.metrics['roc_curve']

                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=roc['fpr'],
                    y=roc['tpr'],
                    mode='lines',
                    name=f"AUC = {roc['auc']:.4f}"
                ))

                fig.add_trace(go.Scatter(
                    x=[0, 1],
                    y=[0, 1],
                    mode='lines',
                    line=dict(dash='dash', color='gray'),
                    showlegend=False
                ))

                fig.update_layout(
                    title="Receiver Operating Characteristic (ROC) Curve",
                    xaxis_title="False Positive Rate",
                    yaxis_title="True Positive Rate",
                    legend=dict(x=0.01, y=0.99)
                )

                st.plotly_chart(fig)

            # Display precision-recall curve
            if 'precision_recall_curve' in st.session_state.identifier.evaluator.metrics:
                st.subheader("Precision-Recall Curve")
                pr = st.session_state.identifier.evaluator.metrics['precision_recall_curve']

                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=pr['recall'],
                    y=pr['precision'],
                    mode='lines',
                    name="Precision-Recall"
                ))

                fig.update_layout(
                    title="Precision-Recall Curve",
                    xaxis_title="Recall",
                    yaxis_title="Precision",
                    legend=dict(x=0.01, y=0.99)
                )

                st.plotly_chart(fig)

    # Display visualizations
    st.subheader("Visualizations")

    # Embedding visualization
    if st.session_state.embeddings_generated:
        # Get embeddings
        embeddings1 = st.session_state.identifier.embeddings[platform1_name]['fusion']
        embeddings2 = st.session_state.identifier.embeddings[platform2_name]['fusion']

        # Create visualization
        fig = make_subplots(specs=[[{"secondary_y": False}]])

        # Create t-SNE visualization
        from sklearn.manifold import TSNE

        # Combine embeddings for dimensionality reduction
        user_ids1 = list(embeddings1.keys())
        user_ids2 = list(embeddings2.keys())

        # Check if there are any embeddings
        if not user_ids1 or not user_ids2:
            st.warning("No embeddings found for one or both platforms.")
            return

        # Check if all embeddings have the same dimension
        dim1 = [embeddings1[uid].shape[0] for uid in user_ids1]
        dim2 = [embeddings2[uid].shape[0] for uid in user_ids2]

        if len(set(dim1)) > 1 or len(set(dim2)) > 1 or set(dim1) != set(dim2):
            st.warning("Embeddings have inconsistent dimensions. Using PCA to normalize dimensions.")

            # Use PCA to normalize dimensions
            from sklearn.decomposition import PCA

            # Find the minimum dimension
            min_dim = min(min(dim1), min(dim2))

            # Apply PCA to each embedding
            normalized_embs1 = {}
            normalized_embs2 = {}

            pca = PCA(n_components=min_dim)

            # Normalize embeddings for platform 1
            for uid in user_ids1:
                emb = embeddings1[uid]
                if emb.shape[0] > min_dim:
                    normalized_embs1[uid] = pca.fit_transform(emb.reshape(1, -1))[0]
                else:
                    normalized_embs1[uid] = emb

            # Normalize embeddings for platform 2
            for uid in user_ids2:
                emb = embeddings2[uid]
                if emb.shape[0] > min_dim:
                    normalized_embs2[uid] = pca.fit_transform(emb.reshape(1, -1))[0]
                else:
                    normalized_embs2[uid] = emb

            # Create embedding matrices
            try:
                emb_matrix1 = np.vstack([normalized_embs1[uid] for uid in user_ids1])
                emb_matrix2 = np.vstack([normalized_embs2[uid] for uid in user_ids2])
            except ValueError as e:
                st.error(f"Error creating embedding matrices: {e}")
                return
        else:
            # All embeddings have the same dimension
            try:
                emb_matrix1 = np.vstack([embeddings1[uid] for uid in user_ids1])
                emb_matrix2 = np.vstack([embeddings2[uid] for uid in user_ids2])
            except ValueError as e:
                st.error(f"Error creating embedding matrices: {e}")
                return

        # Combine embeddings
        try:
            combined_emb = np.vstack([emb_matrix1, emb_matrix2])
        except ValueError as e:
            st.error(f"Error combining embeddings: {e}")
            return

        # Apply t-SNE
        tsne = TSNE(n_components=2, random_state=42)
        reduced_emb = tsne.fit_transform(combined_emb)

        # Split back into platform-specific embeddings
        reduced_emb1 = reduced_emb[:len(user_ids1)]
        reduced_emb2 = reduced_emb[len(user_ids1):]

        # Add scatter plots for each platform
        fig.add_trace(
            go.Scatter(
                x=reduced_emb1[:, 0], y=reduced_emb1[:, 1],
                mode='markers',
                name=platform1_name,
                marker=dict(size=10, color='blue'),
                text=user_ids1,
                hoverinfo='text'
            )
        )

        fig.add_trace(
            go.Scatter(
                x=reduced_emb2[:, 0], y=reduced_emb2[:, 1],
                mode='markers',
                name=platform2_name,
                marker=dict(size=10, color='red'),
                text=user_ids2,
                hoverinfo='text'
            )
        )

        # Add lines for matches if available
        if st.session_state.matches is not None:
            for _, row in st.session_state.matches.iterrows():
                user_id1 = row['user_id1']
                user_id2 = row['user_id2']
                confidence = row['confidence']

                if user_id1 in user_ids1 and user_id2 in user_ids2:
                    idx1 = user_ids1.index(user_id1)
                    idx2 = user_ids2.index(user_id2)

                    x1, y1 = reduced_emb1[idx1]
                    x2, y2 = reduced_emb2[idx2]

                    fig.add_trace(
                        go.Scatter(
                            x=[x1, x2], y=[y1, y2],
                            mode='lines',
                            line=dict(width=1, color='rgba(0, 0, 0, 0.3)'),
                            hoverinfo='text',
                            text=f"Match: {user_id1} - {user_id2}<br>Confidence: {confidence:.3f}",
                            showlegend=False
                        )
                    )

        fig.update_layout(
            title="User Embeddings and Matches",
            xaxis=dict(title='t-SNE Dimension 1'),
            yaxis=dict(title='t-SNE Dimension 2')
        )

        st.plotly_chart(fig, use_container_width=True)

def compare_users():
    """Compare specific users between LinkedIn and Instagram."""
    st.header("LinkedIn-Instagram User Comparison")

    if not st.session_state.data_loaded:
        st.warning("Please load data first from the Data Loading tab.")
        st.info("You need to scrape both LinkedIn and Instagram data to perform user comparison.")
        return

    if not st.session_state.embeddings_generated:
        st.warning("Please run analysis first on the Analysis tab.")
        st.info("This will generate the embeddings needed for user comparison.")
        return

    # Get platform names
    platform_names = list(st.session_state.identifier.data.keys())

    # Check if both LinkedIn and Instagram data are available
    linkedin_exists = "linkedin" in platform_names
    instagram_exists = "instagram" in platform_names

    if not linkedin_exists or not instagram_exists:
        missing_platforms = []
        if not linkedin_exists:
            missing_platforms.append("LinkedIn")
        if not instagram_exists:
            missing_platforms.append("Instagram")

        st.error(f"Missing data for {', '.join(missing_platforms)}.")
        st.info("Please go to the Data Loading tab and scrape data from the missing platform(s).")
        return

    # Set platform names
    platform1_name = "linkedin"
    platform2_name = "instagram"

    # Get user IDs
    user_ids1 = list(st.session_state.identifier.data[platform1_name]['profiles']['user_id'])
    user_ids2 = list(st.session_state.identifier.data[platform2_name]['profiles']['user_id'])

    # User selection
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("LinkedIn User")
        user_id1 = st.selectbox("Select LinkedIn User", user_ids1)

        # Show LinkedIn profile info
        if user_id1:
            profile1 = st.session_state.identifier.data[platform1_name]['profiles'][
                st.session_state.identifier.data[platform1_name]['profiles']['user_id'] == user_id1
            ]
            if not profile1.empty:
                st.info(f"Name: {profile1.iloc[0].get('name', 'N/A')}")
                st.info(f"Headline: {profile1.iloc[0].get('headline', 'N/A')}")
                st.info(f"Location: {profile1.iloc[0].get('location', 'N/A')}")

    with col2:
        st.subheader("Instagram User")
        user_id2 = st.selectbox("Select Instagram User", user_ids2)

        # Show Instagram profile info
        if user_id2:
            profile2 = st.session_state.identifier.data[platform2_name]['profiles'][
                st.session_state.identifier.data[platform2_name]['profiles']['user_id'] == user_id2
            ]
            if not profile2.empty:
                st.info(f"Username: {profile2.iloc[0].get('username', 'N/A')}")
                st.info(f"Full Name: {profile2.iloc[0].get('full_name', 'N/A')}")
                st.info(f"Bio: {profile2.iloc[0].get('bio', 'N/A')}")

    # Compare button
    if st.button("Compare Users"):
        with st.spinner("Comparing users..."):
            # Get user profiles
            profile1 = st.session_state.identifier.data[platform1_name]['profiles'][
                st.session_state.identifier.data[platform1_name]['profiles']['user_id'] == user_id1
            ].iloc[0]

            profile2 = st.session_state.identifier.data[platform2_name]['profiles'][
                st.session_state.identifier.data[platform2_name]['profiles']['user_id'] == user_id2
            ].iloc[0]

            # Get user embeddings
            embedding1 = st.session_state.identifier.embeddings[platform1_name]['fusion'].get(user_id1)
            embedding2 = st.session_state.identifier.embeddings[platform2_name]['fusion'].get(user_id2)

            # Calculate similarity
            if embedding1 is not None and embedding2 is not None:
                from sklearn.metrics.pairwise import cosine_similarity

                # Check if embeddings have the same dimension
                if embedding1.shape[0] != embedding2.shape[0]:
                    st.warning(f"Embeddings have different dimensions: {embedding1.shape[0]} vs {embedding2.shape[0]}. Using PCA to normalize dimensions.")

                    # Use PCA to normalize dimensions
                    from sklearn.decomposition import PCA

                    # Find the minimum dimension
                    min_dim = min(embedding1.shape[0], embedding2.shape[0])

                    # Apply PCA to each embedding
                    pca = PCA(n_components=min_dim)

                    if embedding1.shape[0] > min_dim:
                        embedding1 = pca.fit_transform(embedding1.reshape(1, -1))[0]

                    if embedding2.shape[0] > min_dim:
                        embedding2 = pca.fit_transform(embedding2.reshape(1, -1))[0]

                try:
                    similarity = cosine_similarity(
                        embedding1.reshape(1, -1),
                        embedding2.reshape(1, -1)
                    )[0, 0]
                except ValueError as e:
                    st.error(f"Error calculating similarity: {e}")
                    similarity = None
            else:
                st.warning("One or both embeddings are missing.")
                similarity = None

            # Display profiles
            col1, col2 = st.columns(2)

            with col1:
                st.subheader(f"{platform1_name} Profile")
                st.json(profile1.to_dict())

            with col2:
                st.subheader(f"{platform2_name} Profile")
                st.json(profile2.to_dict())

            # Display similarity
            if similarity is not None:
                st.subheader("Similarity Score")

                # Create gauge chart
                fig = go.Figure(go.Indicator(
                    mode="gauge+number",
                    value=similarity,
                    domain={'x': [0, 1], 'y': [0, 1]},
                    title={'text': "Similarity Score"},
                    gauge={
                        'axis': {'range': [0, 1]},
                        'bar': {'color': "darkblue"},
                        'steps': [
                            {'range': [0, 0.3], 'color': "red"},
                            {'range': [0.3, 0.7], 'color': "yellow"},
                            {'range': [0.7, 1], 'color': "green"}
                        ],
                        'threshold': {
                            'line': {'color': "red", 'width': 4},
                            'thickness': 0.75,
                            'value': st.session_state.identifier.config.get('matching_threshold', 0.7)
                        }
                    }
                ))

                st.plotly_chart(fig)

                # Display match status
                if similarity >= st.session_state.identifier.config.get('matching_threshold', 0.7):
                    st.success("These users are likely the same person.")
                else:
                    st.warning("These users are likely different people.")

def main():
    """Main function for the Streamlit app."""
    st.title("LinkedIn-Instagram User Identification")

    # Sidebar
    st.sidebar.title("Navigation")
    page = st.sidebar.radio("Go to", ["Home", "Data Loading", "Analysis", "Results", "User Comparison"])

    # Display selected page
    if page == "Home":
        st.header("Welcome to LinkedIn-Instagram User Identification")
        st.write("""
        This application helps identify and match users across LinkedIn and Instagram
        using machine learning techniques.

        ### Features
        - Data scraping from LinkedIn and Instagram
        - Preprocessing and normalization of user data
        - Network-based user embeddings (Node2Vec)
        - Semantic embeddings from user content (BERT)
        - Temporal embeddings from user activity patterns
        - Multi-modal embedding fusion
        - User matching across platforms
        - Visualization of matching results

        ### Getting Started
        1. Go to the **Data Loading** page to scrape LinkedIn and Instagram data
        2. Run the analysis on the **Analysis** page
        3. View the results on the **Results** page
        4. Compare specific users on the **User Comparison** page

        ### Important Notes
        - Web scraping may violate the Terms of Service of LinkedIn and Instagram
        - Use this application responsibly and for educational purposes only
        - Ensure you have proper authorization to access the profiles you scrape
        """)

    elif page == "Data Loading":
        load_data()

    elif page == "Analysis":
        run_analysis()

    elif page == "Results":
        display_results()

    elif page == "User Comparison":
        compare_users()

if __name__ == "__main__":
    main()
