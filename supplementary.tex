\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{url}
\usepackage{listings}
\usepackage{tikz}
\usepackage{subcaption}

\begin{document}

\title{Supplementary Material: Privacy-Preserving Cross-Platform User Identification Using Multi-Modal Ensemble Learning with Differential Privacy}

\author{\IEEEauthorblockN{Anonymous Author}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{University Name}\\
City, Country \\
email@university.edu}
}

\maketitle

\section{Detailed Algorithm Descriptions}

\subsection{Multi-Modal Feature Extraction Algorithm}

\begin{algorithm}
\caption{Multi-Modal Feature Extraction}
\label{alg:feature_extraction}
\begin{algorithmic}[1]
\REQUIRE User data $U = \{profiles, posts, network, metadata\}$
\ENSURE Multi-modal embeddings $E = \{e_s, e_n, e_t, e_p\}$
\STATE Initialize embedders: $\{Semantic, Network, Temporal, Profile\}$
\STATE $texts \leftarrow$ Extract text from profiles and posts
\STATE $e_s \leftarrow$ SemanticEmbedder.fit\_transform($texts$)
\STATE $graph \leftarrow$ Construct network graph from connections
\STATE $e_n \leftarrow$ NetworkEmbedder.fit\_transform($graph$)
\STATE $timestamps \leftarrow$ Extract temporal patterns from activity
\STATE $e_t \leftarrow$ TemporalEmbedder.fit\_transform($timestamps$)
\STATE $profiles \leftarrow$ Extract profile features
\STATE $e_p \leftarrow$ ProfileEmbedder.fit\_transform($profiles$)
\RETURN $E = \{e_s, e_n, e_t, e_p\}$
\end{algorithmic}
\end{algorithm}

\subsection{Privacy-Preserving Ensemble Algorithm}

\begin{algorithm}
\caption{Privacy-Preserving Ensemble Matching}
\label{alg:ensemble_matching}
\begin{algorithmic}[1]
\REQUIRE Embeddings $E_1, E_2$ from two platforms, Privacy parameters $\epsilon, \delta$
\ENSURE Privacy-preserving similarity scores $S_{private}$
\STATE Apply differential privacy: $E_1' \leftarrow$ AddNoise($E_1, \epsilon/2$)
\STATE Apply differential privacy: $E_2' \leftarrow$ AddNoise($E_2, \epsilon/2$)
\STATE Initialize matchers: $\{GSMUA, FRUI-P, LightGBM, Cosine\}$
\FOR{each matcher $M_i$}
    \STATE $scores_i \leftarrow M_i$.predict($E_1', E_2'$)
    \STATE $confidence_i \leftarrow M_i$.predict\_proba($E_1', E_2'$)
\ENDFOR
\STATE $S_{ensemble} \leftarrow$ EnsembleCombiner.combine($\{scores_i\}, \{confidence_i\}$)
\STATE $S_{private} \leftarrow$ ApplyPrivacyMechanisms($S_{ensemble}$)
\RETURN $S_{private}$
\end{algorithmic}
\end{algorithm}

\subsection{GDPR Compliance Algorithm}

\begin{algorithm}
\caption{GDPR Compliance Management}
\label{alg:gdpr_compliance}
\begin{algorithmic}[1]
\REQUIRE User data $D$, Consent records $C$, Privacy policy $P$
\ENSURE GDPR-compliant processing
\STATE Check consent: $valid \leftarrow$ CheckConsent($user\_id, purpose$)
\IF{$valid = False$}
    \STATE Request consent or deny processing
    \RETURN
\ENDIF
\STATE Apply data minimization: $D_{min} \leftarrow$ Minimize($D, essential\_fields$)
\STATE Log processing: AuditLog.record($user\_id, action, timestamp$)
\STATE Apply retention policy: $D_{retained} \leftarrow$ ApplyRetention($D_{min}, policy$)
\STATE Process data with privacy protection
\STATE Generate compliance report
\end{algorithmic}
\end{algorithm}

\section{Detailed Experimental Results}

\subsection{Performance Metrics by Dataset Size}

\begin{table}[htbp]
\caption{Performance vs Dataset Size}
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Dataset Size} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Runtime (s)} \\
\hline
100 users & 0.92 & 0.88 & 0.90 & 2.3 \\
500 users & 0.90 & 0.86 & 0.88 & 8.7 \\
1000 users & 0.89 & 0.85 & 0.87 & 15.2 \\
5000 users & 0.87 & 0.83 & 0.85 & 72.1 \\
10000 users & 0.85 & 0.81 & 0.83 & 145.8 \\
\hline
\end{tabular}
\end{center}
\end{table}

\subsection{Privacy Budget Analysis}

\begin{table}[htbp]
\caption{Privacy-Utility Tradeoff}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{$\epsilon$ Value} & \textbf{F1-Score} & \textbf{Privacy Level} & \textbf{Utility Loss} \\
\hline
0.1 & 0.78 & Very High & 10.3\% \\
0.5 & 0.82 & High & 5.7\% \\
1.0 & 0.87 & Medium & 0.0\% \\
2.0 & 0.88 & Low & -1.1\% \\
5.0 & 0.89 & Very Low & -2.3\% \\
\hline
\end{tabular}
\end{center}
\end{table}

\subsection{Component Ablation Study}

\begin{table}[htbp]
\caption{Ablation Study Results}
\begin{center}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Configuration} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
\hline
Semantic only & 0.72 & 0.68 & 0.70 \\
+ Network & 0.76 & 0.72 & 0.74 \\
+ Temporal & 0.79 & 0.75 & 0.77 \\
+ Profile & 0.82 & 0.78 & 0.80 \\
+ Cross-modal attention & 0.86 & 0.82 & 0.84 \\
+ Self-attention & 0.88 & 0.84 & 0.86 \\
+ Ensemble & 0.89 & 0.85 & 0.87 \\
\hline
\end{tabular}
\end{center}
\end{table}

\section{Implementation Details}

\subsection{System Configuration}

\begin{lstlisting}[language=Python, caption=System Configuration Example]
config = {
    'network_embedding_dim': 256,
    'semantic_embedding_dim': 384,
    'temporal_embedding_dim': 128,
    'profile_embedding_dim': 128,
    'fusion': {
        'method': 'cross_modal_attention',
        'hidden_dim': 256,
        'num_heads': 16,
        'dropout': 0.1
    },
    'ensemble': {
        'gsmua': {'hidden_dim': 256, 'num_heads': 8},
        'frui_p': {'iterations': 5, 'damping': 0.85},
        'lgb': {'num_estimators': 500, 'learning_rate': 0.05}
    },
    'privacy': {
        'epsilon': 1.0,
        'delta': 1e-5,
        'k_anonymity': 5,
        'l_diversity': 3
    }
}
\end{lstlisting}

\subsection{Privacy Protection Implementation}

\begin{lstlisting}[language=Python, caption=Differential Privacy Implementation]
def add_differential_privacy_noise(data, epsilon, sensitivity=1.0):
    """Add Laplace noise for differential privacy"""
    scale = sensitivity / epsilon
    noise = np.random.laplace(0, scale, data.shape)
    return data + noise

def apply_k_anonymity(data, quasi_identifiers, k=5):
    """Apply k-anonymity by generalizing quasi-identifiers"""
    grouped = data.groupby(quasi_identifiers)
    small_groups = grouped.filter(lambda x: len(x) < k)
    
    if len(small_groups) > 0:
        data = generalize_small_groups(data, quasi_identifiers, small_groups)
    
    return data
\end{lstlisting}

\section{Computational Complexity Analysis}

\subsection{Time Complexity}

The overall time complexity of our approach is:
\begin{align}
T(n) &= O(n \cdot d_{text} \cdot \log n) + O(n^2 \cdot d_{graph}) \\
&\quad + O(n \cdot d_{temporal}) + O(n \cdot d_{profile}) \\
&\quad + O(n^2 \cdot d_{fused}) + O(k \cdot n^2)
\end{align}

where:
\begin{itemize}
\item $n$ is the number of users
\item $d_{text}, d_{graph}, d_{temporal}, d_{profile}$ are embedding dimensions
\item $d_{fused}$ is the fused embedding dimension
\item $k$ is the number of ensemble matchers
\end{itemize}

\subsection{Space Complexity}

The space complexity is dominated by storing embeddings and intermediate results:
\begin{equation}
S(n) = O(n \cdot (d_{text} + d_{graph} + d_{temporal} + d_{profile} + d_{fused}))
\end{equation}

\section{Privacy Analysis}

\subsection{Differential Privacy Guarantees}

Our implementation provides $(\epsilon, \delta)$-differential privacy with:
\begin{itemize}
\item Sequential composition: $\epsilon_{total} = \sum_{i} \epsilon_i$
\item Parallel composition: $\epsilon_{total} = \max_i \epsilon_i$
\item Advanced composition with privacy amplification
\end{itemize}

\subsection{Information Leakage Analysis}

We measure information leakage using mutual information:
\begin{equation}
I(X; Y) = \sum_{x,y} p(x,y) \log \frac{p(x,y)}{p(x)p(y)}
\end{equation}

Results show minimal information leakage with our privacy mechanisms.

\section{Ethical Considerations}

\subsection{Data Collection Ethics}
All data collection follows institutional ethics guidelines with:
\begin{itemize}
\item Informed consent from participants
\item Anonymization of personal identifiers
\item Secure data storage and transmission
\item Right to data deletion
\end{itemize}

\subsection{Bias Mitigation}
We implement bias detection and mitigation strategies:
\begin{itemize}
\item Demographic parity constraints
\item Equalized odds optimization
\item Fairness-aware ensemble weighting
\end{itemize}

\section{Reproducibility}

\subsection{Code Availability}
Complete implementation is available at: [URL to be provided upon acceptance]

\subsection{Dataset Information}
Synthetic datasets can be generated using our provided scripts. Real-world datasets require ethics approval and data use agreements.

\subsection{Experimental Setup}
All experiments conducted on:
\begin{itemize}
\item Hardware: Intel Xeon E5-2680 v4, 64GB RAM, NVIDIA Tesla V100
\item Software: Python 3.8, PyTorch 1.9, scikit-learn 1.0
\item Operating System: Ubuntu 20.04 LTS
\end{itemize}

\end{document}
